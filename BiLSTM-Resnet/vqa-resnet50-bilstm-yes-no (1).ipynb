{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Libaries"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:15:41.134245Z","iopub.status.busy":"2024-10-20T15:15:41.133726Z","iopub.status.idle":"2024-10-20T15:15:44.264245Z","shell.execute_reply":"2024-10-20T15:15:44.263111Z","shell.execute_reply.started":"2024-10-20T15:15:41.134169Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch                    2.2.0\n","torchdata                0.7.1\n","torchtext                0.17.0\n","torchvision              0.17.0\n","Note: you may need to restart the kernel to use updated packages.\n"]}],"source":["pip list | grep torch"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:15:44.266949Z","iopub.status.busy":"2024-10-20T15:15:44.266011Z","iopub.status.idle":"2024-10-20T15:15:53.394046Z","shell.execute_reply":"2024-10-20T15:15:53.393301Z","shell.execute_reply.started":"2024-10-20T15:15:44.266900Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/nhatthuong/.miniconda3/envs/env_vqa/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n","  from .autonotebook import tqdm as notebook_tqdm\n"]}],"source":["import torch\n","import torch.nn as nn\n","\n","import os\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from sklearn.model_selection import train_test_split\n","\n","import torchtext\n","from torchtext.data.utils import get_tokenizer\n","from torchtext.vocab import build_vocab_from_iterator \n","\n","import spacy\n","import timm\n","\n","from torchvision import transforms"]},{"cell_type":"markdown","metadata":{},"source":["# Load Dataset"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:19:09.686502Z","iopub.status.busy":"2024-10-20T15:19:09.685536Z","iopub.status.idle":"2024-10-20T15:19:09.742542Z","shell.execute_reply":"2024-10-20T15:19:09.741626Z","shell.execute_reply.started":"2024-10-20T15:19:09.686444Z"},"trusted":true},"outputs":[],"source":["# Load train data\n","train_data = []\n","train_set_path = '/home/nhatthuong/Documents/ResearchVQA-VQG-firstpaper/VQA/datasets/vqa_coco_dataset/vaq2.0.TrainImages.txt'\n","\n","with open(train_set_path, 'r') as f:\n","    lines = f.readlines()\n","    for line in lines:\n","        temp = line.split('\\t')\n","        qa = temp[1].split('?')\n","        \n","        if len(qa) == 3:\n","            answer = qa[2]\n","        else: \n","            answer = qa[1]\n","            \n","        data_sample = {\n","            'image_path': temp[0][:-2],\n","            'question': qa[0]+'?',\n","            'answer': answer\n","        }\n","        train_data.append(data_sample)\n","\n","# Tương tự cho val và test data\n","val_data = []\n","val_set_path = '/home/nhatthuong/Documents/ResearchVQA-VQG-firstpaper/VQA/datasets/vqa_coco_dataset/vaq2.0.DevImages.txt'\n","\n","with open(train_set_path, 'r') as f:\n","    lines = f.readlines()\n","    for line in lines:\n","        temp = line.split('\\t')\n","        qa = temp[1].split('?')\n","        \n","        if len(qa) == 3:\n","            answer = qa[2]\n","        else: \n","            answer = qa[1]\n","            \n","        data_sample = {\n","            'image_path': temp[0][:-2],\n","            'question': qa[0]+'?',\n","            'answer': answer\n","        }\n","        train_data.append(data_sample)\n","\n","test_data = []\n","test_set_path = '/home/nhatthuong/Documents/ResearchVQA-VQG-firstpaper/VQA/datasets/vqa_coco_dataset/vaq2.0.TestImages.txt'\n","\n","with open(test_set_path, 'r') as f:\n","    lines = f.readlines()\n","    for line in lines:\n","        temp = line.split('\\t')\n","        qa = temp[1].split('?')\n","        \n","        if len(qa) == 3:\n","            answer = qa[2]\n","        else: \n","            answer = qa[1]\n","            \n","        data_sample = {\n","            'image_path': temp[0][:-2],\n","            'question': qa[0]+'?',\n","            'answer': answer\n","        }\n","        test_data.append(data_sample)"]},{"cell_type":"markdown","metadata":{},"source":["# Dataset Processing"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:19:12.612525Z","iopub.status.busy":"2024-10-20T15:19:12.612103Z","iopub.status.idle":"2024-10-20T15:19:14.236221Z","shell.execute_reply":"2024-10-20T15:19:14.235194Z","shell.execute_reply.started":"2024-10-20T15:19:12.612479Z"},"trusted":true},"outputs":[],"source":["eng = spacy.load(\"en_core_web_sm\") # Load the English model to tokenize English text\n","\n","def get_tokens(data_iter):\n","    for sample in data_iter:\n","        question = sample['question']\n","\n","        yield [token.text for token in eng.tokenizer(question)]\n","\n","\n","vocab = build_vocab_from_iterator(\n","    get_tokens(train_data),\n","    min_freq=2,\n","    specials= ['<pad>', '<sos>', '<eos>', '<unk>'],\n","    special_first=True\n",")\n","vocab.set_default_index(vocab['<unk>'])"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:19:14.583164Z","iopub.status.busy":"2024-10-20T15:19:14.582776Z","iopub.status.idle":"2024-10-20T15:19:14.591176Z","shell.execute_reply":"2024-10-20T15:19:14.590000Z","shell.execute_reply.started":"2024-10-20T15:19:14.583104Z"},"trusted":true},"outputs":[],"source":["classes = set([sample['answer'] for sample in train_data])\n","\n","classes_to_idx = {\n","    cls_name: idx for idx, cls_name in enumerate(classes)\n","}\n","\n","idx_to_classes = {\n","    idx: cls_name for idx, cls_name in enumerate(classes)\n","}"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:19:59.741691Z","iopub.status.busy":"2024-10-20T15:19:59.740989Z","iopub.status.idle":"2024-10-20T15:19:59.747595Z","shell.execute_reply":"2024-10-20T15:19:59.746505Z","shell.execute_reply.started":"2024-10-20T15:19:59.741651Z"},"trusted":true},"outputs":[],"source":["def tokenize(question, max_sequence_length):\n","    tokens = [token.text for token in eng.tokenizer(question)]\n","    sequence = [vocab[token] for token in tokens]\n","    \n","    if len(sequence) < max_sequence_length:\n","        sequence += [vocab['<pad>']] * (max_sequence_length - len(sequence))\n","    else:\n","        sequence = sequence[:max_sequence_length]\n","    \n","    return sequence\n"]},{"cell_type":"markdown","metadata":{},"source":["# Create Pytorch dataset"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:20:03.281283Z","iopub.status.busy":"2024-10-20T15:20:03.280629Z","iopub.status.idle":"2024-10-20T15:20:03.289929Z","shell.execute_reply":"2024-10-20T15:20:03.288834Z","shell.execute_reply.started":"2024-10-20T15:20:03.281237Z"},"trusted":true},"outputs":[],"source":["class VQADataset(Dataset):\n","    def __init__(\n","        self,\n","        data,\n","        classes_to_idx,\n","        max_seq_len=20,\n","        transform=None,\n","        root_dir='/home/nhatthuong/Documents/ResearchVQA-VQG-firstpaper/VQA/datasets/vqa_coco_dataset/val2014-resised'\n","    ):\n","        self.transform = transform\n","        self.data = data\n","        self.max_seq_len = max_seq_len\n","        self.root_dir = root_dir\n","        self.classes_to_idx = classes_to_idx\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, index):\n","        img_path = os.path.join(self.root_dir, self.data[index]['image_path'])\n","        img = Image.open(img_path).convert('RGB')\n","        if self.transform:\n","            img = self.transform(img)\n","\n","        question = self.data[index]['question']\n","        question = tokenize(question, self.max_seq_len)\n","        question = torch.tensor(question, dtype=torch.long)\n","\n","        label = self.data[index]['answer']\n","        label = classes_to_idx[label]\n","        label = torch.tensor(label, dtype=torch.long)\n","\n","        return img, question, label"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:20:05.406132Z","iopub.status.busy":"2024-10-20T15:20:05.405513Z","iopub.status.idle":"2024-10-20T15:20:05.411311Z","shell.execute_reply":"2024-10-20T15:20:05.410203Z","shell.execute_reply.started":"2024-10-20T15:20:05.406092Z"},"trusted":true},"outputs":[],"source":["transform = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","])"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:20:07.217413Z","iopub.status.busy":"2024-10-20T15:20:07.217020Z","iopub.status.idle":"2024-10-20T15:20:07.222755Z","shell.execute_reply":"2024-10-20T15:20:07.221702Z","shell.execute_reply.started":"2024-10-20T15:20:07.217376Z"},"trusted":true},"outputs":[],"source":["train_dataset = VQADataset(\n","    train_data,\n","    classes_to_idx=classes_to_idx,\n","    transform=transform\n",")\n","val_dataset = VQADataset(\n","    val_data,\n","    classes_to_idx=classes_to_idx,\n","    transform=transform\n",")\n","test_dataset = VQADataset(\n","    test_data,\n","    classes_to_idx=classes_to_idx,\n","    transform=transform\n",")"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:20:08.825790Z","iopub.status.busy":"2024-10-20T15:20:08.824837Z","iopub.status.idle":"2024-10-20T15:20:08.831241Z","shell.execute_reply":"2024-10-20T15:20:08.830390Z","shell.execute_reply.started":"2024-10-20T15:20:08.825747Z"},"trusted":true},"outputs":[],"source":["train_batch_size = 128\n","test_batch_size = 32\n","\n","train_loader = DataLoader(\n","    train_dataset,\n","    batch_size=train_batch_size,\n","    shuffle=True\n",")\n","val_loader = DataLoader(\n","    val_dataset,\n","    batch_size=test_batch_size,\n","    shuffle=False\n",")\n","test_loader = DataLoader(\n","    test_dataset,\n","    batch_size=test_batch_size,\n","    shuffle=False\n",")"]},{"cell_type":"markdown","metadata":{},"source":["# Create Model ResNet50 + BiLSTM"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:20:10.575883Z","iopub.status.busy":"2024-10-20T15:20:10.575501Z","iopub.status.idle":"2024-10-20T15:20:10.586029Z","shell.execute_reply":"2024-10-20T15:20:10.585021Z","shell.execute_reply.started":"2024-10-20T15:20:10.575843Z"},"trusted":true},"outputs":[],"source":["class VQAModel(nn.Module):\n","    def __init__(\n","        self,\n","        n_classes,\n","        img_model_name='resnet50',\n","        embeddding_dim=300,\n","        n_layers=1,\n","        hidden_size=128,\n","        dropout_prob=0.2\n","    ):\n","        super(VQAModel, self).__init__()\n","        self.image_encoder = timm.create_model(\n","            img_model_name,\n","            pretrained=True,\n","            num_classes=hidden_size\n","        )\n","\n","        self.embedding = nn.Embedding(len(vocab), embeddding_dim)\n","        self.lstm1 = nn.LSTM(\n","            input_size=embeddding_dim,\n","            hidden_size=hidden_size,\n","            num_layers=n_layers,\n","            batch_first=True,\n","            bidirectional=True\n","        )\n","        self.lstm2 = nn.LSTM(\n","            input_size=hidden_size*3,\n","            hidden_size=hidden_size,\n","            num_layers=n_layers,\n","            batch_first=True,\n","            bidirectional=True\n","        )\n","        self.dropout = nn.Dropout(dropout_prob)\n","        self.fc = nn.Linear(hidden_size * 2, n_classes)\n","\n","    def forward(self, img, text):\n","        img_features = self.image_encoder(img)\n","\n","        text_emb = self.embedding(text)\n","        lstm_out, _ = self.lstm1(text_emb)\n","\n","        lstm_out = lstm_out[:, -1, :]\n","\n","        combined = torch.cat((img_features, lstm_out), dim=1)\n","        x, _ = self.lstm2(combined)\n","        x = self.dropout(x)\n","        x = self.fc(x)\n","\n","        return x"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:20:13.063748Z","iopub.status.busy":"2024-10-20T15:20:13.062828Z","iopub.status.idle":"2024-10-20T15:20:13.567322Z","shell.execute_reply":"2024-10-20T15:20:13.566534Z","shell.execute_reply.started":"2024-10-20T15:20:13.063706Z"},"trusted":true},"outputs":[],"source":["n_classes = len(classes)\n","img_model_name = 'resnet50'\n","hidden_size = 128\n","n_layers = 1\n","embeddding_dim = 64\n","dropout_prob = 0.2\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","\n","model = VQAModel(\n","    n_classes=n_classes,\n","    img_model_name=img_model_name,\n","    embeddding_dim=embeddding_dim,\n","    n_layers=n_layers,\n","    hidden_size=hidden_size,\n","    dropout_prob=dropout_prob\n",").to(device)"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:20:15.056023Z","iopub.status.busy":"2024-10-20T15:20:15.055309Z","iopub.status.idle":"2024-10-20T15:20:16.503633Z","shell.execute_reply":"2024-10-20T15:20:16.502671Z","shell.execute_reply.started":"2024-10-20T15:20:15.055985Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([128, 2])\n"]}],"source":["images, questions, labels = next(iter(train_loader))\n","\n","model.eval()\n","with torch.no_grad():\n","    images = images.to(device)\n","    questions = questions.to(device)\n","    output = model(images, questions)\n","    print(output.shape)"]},{"cell_type":"markdown","metadata":{},"source":["# Training "]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:20:18.550151Z","iopub.status.busy":"2024-10-20T15:20:18.549302Z","iopub.status.idle":"2024-10-20T15:20:18.557530Z","shell.execute_reply":"2024-10-20T15:20:18.556514Z","shell.execute_reply.started":"2024-10-20T15:20:18.550109Z"},"trusted":true},"outputs":[],"source":["def evaluate(model, dataloader, criterion, device):\n","    model.eval()\n","    correct = 0\n","    total = 0\n","    losses = []\n","    with torch.no_grad():\n","        for image, question, labels in dataloader:\n","            image, question, labels = image.to(device), question.to(device), labels.to(device)\n","            outputs = model(image, question)\n","            loss = criterion(outputs, labels)\n","            losses.append(loss.item())\n","            _, predicted = torch.max(outputs.data, 1)\n","            total += labels.size(0)\n","            correct += (predicted == labels).sum().item()\n","\n","    loss = sum(losses) / len(losses)\n","    acc = correct / total\n","\n","    return loss, acc"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:20:32.618047Z","iopub.status.busy":"2024-10-20T15:20:32.617430Z","iopub.status.idle":"2024-10-20T15:20:32.626989Z","shell.execute_reply":"2024-10-20T15:20:32.625995Z","shell.execute_reply.started":"2024-10-20T15:20:32.618008Z"},"trusted":true},"outputs":[],"source":["def fit(\n","    model,\n","    train_loader,\n","    val_loader,\n","    criterion,\n","    optimizer,\n","    scheduler,\n","    device,\n","    epochs\n","):\n","    train_losses = []\n","    val_losses = []\n","\n","    for epoch in range(epochs):\n","        batch_train_losses = []\n","\n","        model.train()\n","        for idx, (images, questions, labels) in enumerate(train_loader):\n","            images = images.to(device)\n","            questions = questions.to(device)\n","            labels = labels.to(device)\n","\n","            optimizer.zero_grad()\n","            outputs = model(images, questions)\n","\n","            loss = criterion(outputs, labels)\n","            loss.backward()\n","            optimizer.step()\n","\n","            batch_train_losses.append(loss.item())\n","\n","        train_loss = sum(batch_train_losses) / len(batch_train_losses)\n","        train_losses.append(train_loss)\n","\n","        val_loss, val_acc = evaluate(\n","            model, val_loader,\n","            criterion, device\n","        )\n","        val_losses.append(val_loss)\n","\n","        print(f'EPOCH {epoch + 1}:\\tTrain loss: {train_loss:.4f}\\tVal loss: {val_loss:.4f}\\tVal Acc: {val_acc}')\n","\n","        scheduler.step()\n","\n","    return train_losses, val_losses"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:20:35.951730Z","iopub.status.busy":"2024-10-20T15:20:35.950696Z","iopub.status.idle":"2024-10-20T15:20:35.958413Z","shell.execute_reply":"2024-10-20T15:20:35.957563Z","shell.execute_reply.started":"2024-10-20T15:20:35.951687Z"},"trusted":true},"outputs":[],"source":["lr = 1e-2\n","epochs = 50\n","\n","scheduler_step_size = epochs * 0.6\n","criterion = nn.CrossEntropyLoss()\n","\n","optimizer = torch.optim.Adam(\n","    model.parameters(),\n","    lr=lr\n",")\n","scheduler = torch.optim.lr_scheduler.StepLR(\n","    optimizer,\n","    step_size=scheduler_step_size,\n","    gamma=0.1\n",")"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-20T15:20:38.077563Z","iopub.status.busy":"2024-10-20T15:20:38.077149Z"},"trusted":true},"outputs":[{"ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 11.66 GiB of which 59.94 MiB is free. Including non-PyTorch memory, this process has 11.01 GiB memory in use. Of the allocated memory 10.67 GiB is allocated by PyTorch, and 178.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[15], line 27\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs)\u001b[0m\n\u001b[1;32m     24\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(images, questions)\n\u001b[1;32m     26\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[0;32m---> 27\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     30\u001b[0m batch_train_losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n","File \u001b[0;32m~/.miniconda3/envs/env_vqa/lib/python3.10/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m~/.miniconda3/envs/env_vqa/lib/python3.10/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 11.66 GiB of which 59.94 MiB is free. Including non-PyTorch memory, this process has 11.01 GiB memory in use. Of the allocated memory 10.67 GiB is allocated by PyTorch, and 178.43 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}],"source":["train_losses, val_losses = fit(\n","    model,\n","    train_loader,\n","    val_loader,\n","    criterion,\n","    optimizer,\n","    scheduler,\n","    device,\n","    epochs\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["fig, ax = plt.subplots(1, 2, figsize=(12, 5))\n","ax[0].plot(train_losses)\n","ax[0].set_title('Training Loss')\n","ax[0].set_xlabel('Epoch')\n","ax[0].set_ylabel('Loss')\n","ax[1].plot(val_losses, color='orange')\n","ax[1].set_title('Val Loss')\n","ax[1].set_xlabel('Epoch')\n","ax[1].set_ylabel('Loss')\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["# Evaluation"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["val_loss, val_acc = evaluate(\n","    model,\n","    val_loader,\n","    criterion,\n","    device\n",")\n","test_loss, test_acc = evaluate(\n","    model,\n","    test_loader,\n","    criterion,\n","    device\n",")\n","\n","print('Evaluation on val/test dataset')\n","print('Val accuracy: ', val_acc)\n","print('Test accuracy: ', test_acc)"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":2264789,"sourceId":3798293,"sourceType":"datasetVersion"},{"datasetId":5910170,"sourceId":9671427,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"env_vqa","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.15"}},"nbformat":4,"nbformat_minor":4}
