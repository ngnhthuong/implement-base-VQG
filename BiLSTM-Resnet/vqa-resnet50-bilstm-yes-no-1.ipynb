{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3798293,"sourceType":"datasetVersion","datasetId":2264789},{"sourceId":9671427,"sourceType":"datasetVersion","datasetId":5910170}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Libaries","metadata":{}},{"cell_type":"code","source":"pip install torch==2.2.0 torchvision==0.17.0 torchtext==0.17.0 spacy pandas matplotlib Pillow scikit-learn","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:13:26.418694Z","iopub.execute_input":"2024-10-20T15:13:26.418995Z","iopub.status.idle":"2024-10-20T15:15:41.130782Z","shell.execute_reply.started":"2024-10-20T15:13:26.418961Z","shell.execute_reply":"2024-10-20T15:15:41.129447Z"}},"outputs":[{"name":"stdout","text":"Collecting torch==2.2.0\n  Downloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl.metadata (25 kB)\nCollecting torchvision==0.17.0\n  Downloading torchvision-0.17.0-cp310-cp310-manylinux1_x86_64.whl.metadata (6.6 kB)\nCollecting torchtext==0.17.0\n  Downloading torchtext-0.17.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.6 kB)\nRequirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (3.7.5)\nRequirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (10.3.0)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.2.0) (2024.6.1)\nCollecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.2.0)\n  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.2.0)\n  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.2.0)\n  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.2.0)\n  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.2.0)\n  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.2.0)\n  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.2.106 (from torch==2.2.0)\n  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.2.0)\n  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.2.0)\n  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-nccl-cu12==2.19.3 (from torch==2.2.0)\n  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\nCollecting nvidia-nvtx-cu12==12.1.105 (from torch==2.2.0)\n  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\nCollecting triton==2.2.0 (from torch==2.2.0)\n  Downloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.17.0) (1.26.4)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision==0.17.0) (2.32.3)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from torchtext==0.17.0) (4.66.4)\nCollecting torchdata==0.7.1 (from torchtext==0.17.0)\n  Downloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\nCollecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch==2.2.0)\n  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: urllib3>=1.25 in /opt/conda/lib/python3.10/site-packages (from torchdata==0.7.1->torchtext==0.17.0) (1.26.18)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.12.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.9.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (70.0.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas) (2024.1)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.2.1)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (4.53.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (1.4.5)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib) (3.1.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.14.1)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.4.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (3.5.0)\nRequirement already satisfied: language-data>=1.2 in /opt/conda/lib/python3.10/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\nRequirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.17.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.17.0) (3.7)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision==0.17.0) (2024.8.30)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\nRequirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: shellingham>=1.3.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.7.1)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.2.0) (2.1.5)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch==2.2.0) (1.3.0)\nRequirement already satisfied: marisa-trie>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\nRequirement already satisfied: wrapt in /opt/conda/lib/python3.10/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\nDownloading torch-2.2.0-cp310-cp310-manylinux1_x86_64.whl (755.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.5/755.5 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchvision-0.17.0-cp310-cp310-manylinux1_x86_64.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading torchtext-0.17.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading torchdata-0.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading triton-2.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (167.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: triton, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchdata, torchtext\n  Attempting uninstall: torch\n    Found existing installation: torch 2.4.0\n    Uninstalling torch-2.4.0:\n      Successfully uninstalled torch-2.4.0\n  Attempting uninstall: torchvision\n    Found existing installation: torchvision 0.19.0\n    Uninstalling torchvision-0.19.0:\n      Successfully uninstalled torchvision-0.19.0\nSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 torch-2.2.0 torchdata-0.7.1 torchtext-0.17.0 torchvision-0.17.0 triton-2.2.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip list | grep torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:15:41.133726Z","iopub.execute_input":"2024-10-20T15:15:41.134245Z","iopub.status.idle":"2024-10-20T15:15:44.264245Z","shell.execute_reply.started":"2024-10-20T15:15:41.134169Z","shell.execute_reply":"2024-10-20T15:15:44.263111Z"}},"outputs":[{"name":"stdout","text":"pytorch-ignite                           0.5.1\npytorch-lightning                        2.4.0\ntorch                                    2.2.0\ntorchaudio                               2.4.0\ntorchdata                                0.7.1\ntorchinfo                                1.8.0\ntorchmetrics                             1.4.2\ntorchtext                                0.17.0\ntorchvision                              0.17.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\n\nimport torchtext\nfrom torchtext.data.utils import get_tokenizer\nfrom torchtext.vocab import build_vocab_from_iterator \n\nimport spacy\nimport timm\n\nfrom torchvision import transforms","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:15:44.266011Z","iopub.execute_input":"2024-10-20T15:15:44.266949Z","iopub.status.idle":"2024-10-20T15:15:53.394046Z","shell.execute_reply.started":"2024-10-20T15:15:44.266900Z","shell.execute_reply":"2024-10-20T15:15:53.393301Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"# Load train data\ntrain_data = []\ntrain_set_path = '/kaggle/input/vqa-coco-dataset/vaq2.0.TrainImages.txt'\n\nwith open(train_set_path, 'r') as f:\n    lines = f.readlines()\n    for line in lines:\n        temp = line.split('\\t')\n        qa = temp[1].split('?')\n        \n        if len(qa) == 3:\n            answer = qa[2]\n        else: \n            answer = qa[1]\n            \n        data_sample = {\n            'image_path': temp[0][:-2],\n            'question': qa[0]+'?',\n            'answer': answer\n        }\n        train_data.append(data_sample)\n\n# Tương tự cho val và test data\nval_data = []\nval_set_path = '/kaggle/input/vqa-coco-dataset/vaq2.0.DevImages.txt'\n\nwith open(train_set_path, 'r') as f:\n    lines = f.readlines()\n    for line in lines:\n        temp = line.split('\\t')\n        qa = temp[1].split('?')\n        \n        if len(qa) == 3:\n            answer = qa[2]\n        else: \n            answer = qa[1]\n            \n        data_sample = {\n            'image_path': temp[0][:-2],\n            'question': qa[0]+'?',\n            'answer': answer\n        }\n        train_data.append(data_sample)\n\ntest_data = []\ntest_set_path = '/kaggle/input/vqa-coco-dataset/vaq2.0.TestImages.txt'\n\nwith open(test_set_path, 'r') as f:\n    lines = f.readlines()\n    for line in lines:\n        temp = line.split('\\t')\n        qa = temp[1].split('?')\n        \n        if len(qa) == 3:\n            answer = qa[2]\n        else: \n            answer = qa[1]\n            \n        data_sample = {\n            'image_path': temp[0][:-2],\n            'question': qa[0]+'?',\n            'answer': answer\n        }\n        test_data.append(data_sample)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:19:09.685536Z","iopub.execute_input":"2024-10-20T15:19:09.686502Z","iopub.status.idle":"2024-10-20T15:19:09.742542Z","shell.execute_reply.started":"2024-10-20T15:19:09.686444Z","shell.execute_reply":"2024-10-20T15:19:09.741626Z"}},"outputs":[],"execution_count":20},{"cell_type":"markdown","source":"# Dataset Processing","metadata":{}},{"cell_type":"code","source":"eng = spacy.load(\"en_core_web_sm\") # Load the English model to tokenize English text\n\ndef get_tokens(data_iter):\n    for sample in data_iter:\n        question = sample['question']\n\n        yield [token.text for token in eng.tokenizer(question)]\n\n\nvocab = build_vocab_from_iterator(\n    get_tokens(train_data),\n    min_freq=2,\n    specials= ['<pad>', '<sos>', '<eos>', '<unk>'],\n    special_first=True\n)\nvocab.set_default_index(vocab['<unk>'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:19:12.612103Z","iopub.execute_input":"2024-10-20T15:19:12.612525Z","iopub.status.idle":"2024-10-20T15:19:14.236221Z","shell.execute_reply.started":"2024-10-20T15:19:12.612479Z","shell.execute_reply":"2024-10-20T15:19:14.235194Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"classes = set([sample['answer'] for sample in train_data])\n\nclasses_to_idx = {\n    cls_name: idx for idx, cls_name in enumerate(classes)\n}\n\nidx_to_classes = {\n    idx: cls_name for idx, cls_name in enumerate(classes)\n}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:19:14.582776Z","iopub.execute_input":"2024-10-20T15:19:14.583164Z","iopub.status.idle":"2024-10-20T15:19:14.591176Z","shell.execute_reply.started":"2024-10-20T15:19:14.583104Z","shell.execute_reply":"2024-10-20T15:19:14.590000Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def tokenize(question, max_sequence_length):\n    tokens = [token.text for token in eng.tokenizer(question)]\n    sequence = [vocab[token] for token in tokens]\n    \n    if len(sequence) < max_sequence_length:\n        sequence += [vocab['<pad>']] * (max_sequence_length - len(sequence))\n    else:\n        sequence = sequence[:max_sequence_length]\n    \n    return sequence\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:19:59.740989Z","iopub.execute_input":"2024-10-20T15:19:59.741691Z","iopub.status.idle":"2024-10-20T15:19:59.747595Z","shell.execute_reply.started":"2024-10-20T15:19:59.741651Z","shell.execute_reply":"2024-10-20T15:19:59.746505Z"}},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":"# Create Pytorch dataset","metadata":{}},{"cell_type":"code","source":"class VQADataset(Dataset):\n    def __init__(\n        self,\n        data,\n        classes_to_idx,\n        max_seq_len=20,\n        transform=None,\n        root_dir='/kaggle/input/vqa-coco-dataset/val2014-resised'\n    ):\n        self.transform = transform\n        self.data = data\n        self.max_seq_len = max_seq_len\n        self.root_dir = root_dir\n        self.classes_to_idx = classes_to_idx\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        img_path = os.path.join(self.root_dir, self.data[index]['image_path'])\n        img = Image.open(img_path).convert('RGB')\n        if self.transform:\n            img = self.transform(img)\n\n        question = self.data[index]['question']\n        question = tokenize(question, self.max_seq_len)\n        question = torch.tensor(question, dtype=torch.long)\n\n        label = self.data[index]['answer']\n        label = classes_to_idx[label]\n        label = torch.tensor(label, dtype=torch.long)\n\n        return img, question, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:20:03.280629Z","iopub.execute_input":"2024-10-20T15:20:03.281283Z","iopub.status.idle":"2024-10-20T15:20:03.289929Z","shell.execute_reply.started":"2024-10-20T15:20:03.281237Z","shell.execute_reply":"2024-10-20T15:20:03.288834Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:20:05.405513Z","iopub.execute_input":"2024-10-20T15:20:05.406132Z","iopub.status.idle":"2024-10-20T15:20:05.411311Z","shell.execute_reply.started":"2024-10-20T15:20:05.406092Z","shell.execute_reply":"2024-10-20T15:20:05.410203Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"train_dataset = VQADataset(\n    train_data,\n    classes_to_idx=classes_to_idx,\n    transform=transform\n)\nval_dataset = VQADataset(\n    val_data,\n    classes_to_idx=classes_to_idx,\n    transform=transform\n)\ntest_dataset = VQADataset(\n    test_data,\n    classes_to_idx=classes_to_idx,\n    transform=transform\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:20:07.217020Z","iopub.execute_input":"2024-10-20T15:20:07.217413Z","iopub.status.idle":"2024-10-20T15:20:07.222755Z","shell.execute_reply.started":"2024-10-20T15:20:07.217376Z","shell.execute_reply":"2024-10-20T15:20:07.221702Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"train_batch_size = 128\ntest_batch_size = 32\n\ntrain_loader = DataLoader(\n    train_dataset,\n    batch_size=train_batch_size,\n    shuffle=True\n)\nval_loader = DataLoader(\n    val_dataset,\n    batch_size=test_batch_size,\n    shuffle=False\n)\ntest_loader = DataLoader(\n    test_dataset,\n    batch_size=test_batch_size,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:20:08.824837Z","iopub.execute_input":"2024-10-20T15:20:08.825790Z","iopub.status.idle":"2024-10-20T15:20:08.831241Z","shell.execute_reply.started":"2024-10-20T15:20:08.825747Z","shell.execute_reply":"2024-10-20T15:20:08.830390Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"# Create Model ResNet50 + BiLSTM","metadata":{}},{"cell_type":"code","source":"class VQAModel(nn.Module):\n    def __init__(\n        self,\n        n_classes,\n        img_model_name='resnet50',\n        embeddding_dim=300,\n        n_layers=2,\n        hidden_size=128,\n        dropout_prob=0.2\n    ):\n        super(VQAModel, self).__init__()\n        \n        # Image encoder using a pre-trained model from timm\n        self.image_encoder = timm.create_model(\n            img_model_name,\n            pretrained=True,\n            num_classes=hidden_size\n        )\n        \n        # Text embedding layer\n        self.embedding = nn.Embedding(len(vocab), embeddding_dim)\n        \n        # LSTM layer for text processing\n        self.lstm = nn.LSTM(\n            input_size=embeddding_dim,\n            hidden_size=hidden_size,\n            num_layers=n_layers,\n            batch_first=True,\n            bidirectional=True\n        )\n        \n        # Layer normalization\n        self.layernorm = nn.LayerNorm(hidden_size * 2)\n        \n        # Fully connected layers\n        self.fc1 = nn.Linear(hidden_size * 3, 256)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout_prob)\n        self.fc2 = nn.Linear(256, n_classes)\n    \n    def forward(self, img, text):\n        # Process image through image encoder\n        img_features = self.image_encoder(img)\n        \n        # Embed text and process through LSTM\n        text_emb = self.embedding(text)\n        lstm_out, _ = self.lstm(text_emb)\n        \n        # Take the last output of the LSTM\n        lstm_out = lstm_out[:, -1, :]\n        lstm_out = self.layernorm(lstm_out)\n        \n        # Concatenate image and text features\n        combined = torch.cat((img_features, lstm_out), dim=1)\n        \n        # Pass through fully connected layers\n        x = self.fc1(combined)\n        x = self.relu(x)\n        x = self.dropout(x)\n        x = self.fc2(x)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:28:55.552511Z","iopub.execute_input":"2024-10-20T15:28:55.553292Z","iopub.status.idle":"2024-10-20T15:28:55.564208Z","shell.execute_reply.started":"2024-10-20T15:28:55.553253Z","shell.execute_reply":"2024-10-20T15:28:55.563173Z"}},"outputs":[],"execution_count":42},{"cell_type":"code","source":"n_classes = len(classes)\nimg_model_name = 'resnet50'\nhidden_size = 128\nn_layers = 1\nembeddding_dim = 64\ndropout_prob = 0.2\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel = VQAModel(\n    n_classes=n_classes,\n    img_model_name=img_model_name,\n    embeddding_dim=embeddding_dim,\n    n_layers=n_layers,\n    hidden_size=hidden_size,\n    dropout_prob=dropout_prob\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:28:58.050488Z","iopub.execute_input":"2024-10-20T15:28:58.051152Z","iopub.status.idle":"2024-10-20T15:28:58.597895Z","shell.execute_reply.started":"2024-10-20T15:28:58.051114Z","shell.execute_reply":"2024-10-20T15:28:58.597103Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"images, questions, labels = next(iter(train_loader))\n\nmodel.eval()\nwith torch.no_grad():\n    images = images.to(device)\n    questions = questions.to(device)\n    output = model(images, questions)\n    print(output.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:28:59.794690Z","iopub.execute_input":"2024-10-20T15:28:59.795578Z","iopub.status.idle":"2024-10-20T15:29:00.689042Z","shell.execute_reply.started":"2024-10-20T15:28:59.795536Z","shell.execute_reply":"2024-10-20T15:29:00.688083Z"}},"outputs":[{"name":"stdout","text":"torch.Size([128, 2])\n","output_type":"stream"}],"execution_count":44},{"cell_type":"markdown","source":"# Training ","metadata":{}},{"cell_type":"code","source":"def evaluate(model, dataloader, criterion, device):\n    model.eval()\n    correct = 0\n    total = 0\n    losses = []\n    with torch.no_grad():\n        for image, question, labels in dataloader:\n            image, question, labels = image.to(device), question.to(device), labels.to(device)\n            outputs = model(image, question)\n            loss = criterion(outputs, labels)\n            losses.append(loss.item())\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n\n    loss = sum(losses) / len(losses)\n    acc = correct / total\n\n    return loss, acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:29:02.587637Z","iopub.execute_input":"2024-10-20T15:29:02.587999Z","iopub.status.idle":"2024-10-20T15:29:02.595351Z","shell.execute_reply.started":"2024-10-20T15:29:02.587966Z","shell.execute_reply":"2024-10-20T15:29:02.594355Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"def fit(\n    model,\n    train_loader,\n    val_loader,\n    criterion,\n    optimizer,\n    scheduler,\n    device,\n    epochs\n):\n    train_losses = []\n    val_losses = []\n\n    for epoch in range(epochs):\n        batch_train_losses = []\n\n        model.train()\n        for idx, (images, questions, labels) in enumerate(train_loader):\n            images = images.to(device)\n            questions = questions.to(device)\n            labels = labels.to(device)\n\n            optimizer.zero_grad()\n            outputs = model(images, questions)\n\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            batch_train_losses.append(loss.item())\n\n        train_loss = sum(batch_train_losses) / len(batch_train_losses)\n        train_losses.append(train_loss)\n\n        val_loss, val_acc = evaluate(\n            model, val_loader,\n            criterion, device\n        )\n        val_losses.append(val_loss)\n\n        print(f'EPOCH {epoch + 1}:\\tTrain loss: {train_loss:.4f}\\tVal loss: {val_loss:.4f}\\tVal Acc: {val_acc}')\n\n        scheduler.step()\n\n    return train_losses, val_losses","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:29:05.179972Z","iopub.execute_input":"2024-10-20T15:29:05.180401Z","iopub.status.idle":"2024-10-20T15:29:05.189179Z","shell.execute_reply.started":"2024-10-20T15:29:05.180361Z","shell.execute_reply":"2024-10-20T15:29:05.188250Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"lr = 1e-2\nepochs = 50\n\nscheduler_step_size = epochs * 0.6\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(\n    model.parameters(),\n    lr=lr\n)\nscheduler = torch.optim.lr_scheduler.StepLR(\n    optimizer,\n    step_size=scheduler_step_size,\n    gamma=0.1\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:29:07.200438Z","iopub.execute_input":"2024-10-20T15:29:07.201328Z","iopub.status.idle":"2024-10-20T15:29:07.208483Z","shell.execute_reply.started":"2024-10-20T15:29:07.201286Z","shell.execute_reply":"2024-10-20T15:29:07.207518Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"train_losses, val_losses = fit(\n    model,\n    train_loader,\n    val_loader,\n    criterion,\n    optimizer,\n    scheduler,\n    device,\n    epochs\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:29:08.966999Z","iopub.execute_input":"2024-10-20T15:29:08.967823Z","iopub.status.idle":"2024-10-20T15:32:34.256823Z","shell.execute_reply.started":"2024-10-20T15:29:08.967778Z","shell.execute_reply":"2024-10-20T15:32:34.255645Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[46], line 35\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(model, train_loader, val_loader, criterion, optimizer, scheduler, device, epochs)\u001b[0m\n\u001b[1;32m     32\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(batch_train_losses) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_train_losses)\n\u001b[1;32m     33\u001b[0m train_losses\u001b[38;5;241m.\u001b[39mappend(train_loss)\n\u001b[0;32m---> 35\u001b[0m val_loss, val_acc \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m val_losses\u001b[38;5;241m.\u001b[39mappend(val_loss)\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEPOCH \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mTrain loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mVal loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mVal Acc: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_acc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[45], line 16\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(model, dataloader, criterion, device)\u001b[0m\n\u001b[1;32m     13\u001b[0m         total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     14\u001b[0m         correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (predicted \u001b[38;5;241m==\u001b[39m labels)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m---> 16\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlosses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m acc \u001b[38;5;241m=\u001b[39m correct \u001b[38;5;241m/\u001b[39m total\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss, acc\n","\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"],"ename":"ZeroDivisionError","evalue":"division by zero","output_type":"error"}],"execution_count":48},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 2, figsize=(12, 5))\nax[0].plot(train_losses)\nax[0].set_title('Training Loss')\nax[0].set_xlabel('Epoch')\nax[0].set_ylabel('Loss')\nax[1].plot(val_losses, color='orange')\nax[1].set_title('Val Loss')\nax[1].set_xlabel('Epoch')\nax[1].set_ylabel('Loss')\nplt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:24:25.428490Z","iopub.status.idle":"2024-10-20T15:24:25.428833Z","shell.execute_reply.started":"2024-10-20T15:24:25.428665Z","shell.execute_reply":"2024-10-20T15:24:25.428682Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"val_loss, val_acc = evaluate(\n    model,\n    val_loader,\n    criterion,\n    device\n)\ntest_loss, test_acc = evaluate(\n    model,\n    test_loader,\n    criterion,\n    device\n)\n\nprint('Evaluation on val/test dataset')\nprint('Val accuracy: ', val_acc)\nprint('Test accuracy: ', test_acc)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-10-20T15:24:25.430442Z","iopub.status.idle":"2024-10-20T15:24:25.430922Z","shell.execute_reply.started":"2024-10-20T15:24:25.430680Z","shell.execute_reply":"2024-10-20T15:24:25.430704Z"}},"outputs":[],"execution_count":null}]}